2.2   Terminology

      Although the common language definition of ‘similarity’ is sufficient to give an intuitive sense
      of the term, the multitude of ways in which two artifacts can be said to be similar poses a
      challenge when attempting to describe the purpose and behavior of approximate matching
      algorithms. For example, two strings ‘ababa’ and ‘cdcdc’ might be considered similar in that
      they both have five characters ranging over two alternating values, or they might be treated as
      dissimilar because they have no common characters. To resolve this ambiguity, approximate
      matching algorithms define similarity in terms of features that represent characteristics of the
      artifacts pertinent to the algorithm’s method of comparison.

           Features. The basic elements through which artifacts are compared. Comparison
           of two features always yields a binary {0, 1} outcome indicating a match or non-
           match; because features are defined as the most basic comparison unit that the
           algorithm considers, partial matches are not permitted. Generally, a feature can be
           any value derived from an artifact. Each approximate matching algorithm must
           define the structure of its features and the method by which they are derived. For
           example, an algorithm might define a feature as a (byte, offset) pair produced by
           reading the value of a byte and storing it along with the offset at which it was read.
           Feature set. The set of all features associated with a single artifact is its feature
           set. Each algorithm must include a criteria by which candidate features are selected
           for inclusion in this set. For example, an algorithm might select all the (byte,
           offset) pairs produced by reading every 16th byte in the artifact.
           Similarity. The similarity of two artifacts, as measured by a particular approximate
           matching algorithm, is defined as an increasing monotonic function of the number
           of matching features contained in their respective feature sets.

      Based on the level of abstraction of the similarity analysis performed, approximate matching
      methods can be placed in one of three main categories [4]:

            Bytewise matching relies only on the sequences of bytes that make up a digital
            object, without reference to any structures within the data stream, or to any
            meaning the byte stream may have when appropriately interpreted. Such
            methods have the widest applicability as they can be applied to any piece of data;
            however, they also carry the implicit assumption that artifacts that humans
            perceive as similar have similar byte-level encodings. This assumption is not
            universally valid. Analyst expertise is necessary to evaluate the significance of a
            byte-level match.
            Syntactic matching uses internal structures present in digital objects. For ex­
            ample, the structure of a TCP network packet is defined by an international
            standard and matching tools can make use of this structure during network
            packet analysis to match the source, destination or content of the packet. Syntax-
            sensitive similarity measurements are specific to a particular class of objects that
            share an encoding but require no interpretation of the content to produce
            meaningful results.
            Semantic matching uses contextual attributes of the digital object to interpret the
            artifact in a manner that more closely corresponds with human perceptual
            categories. For example, perceptual hashes allow the matching of visually similar
            images and are unconcerned with the low-level details of how the images are
                                                 3
