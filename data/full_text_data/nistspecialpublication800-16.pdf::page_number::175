Information Technology Security Training Requirements

   involve comparison by a subject-matter expert of outputs produced by a student both before
   and after training. They can involve some form of benchmarking, or evaluation of the
  particular training activity in relation to other options for a particular job performance
  measure.    In all cases they involve quantifying the value of resulting improvement in relation
  to the cost of training. Level 4 evaluations, properly designed, can help senior management
  officials to answer such hypothetical questions as: "Is it more cost-effective to devote limited
  training resources to the education of a single, newly-appointed IT security specialist in this
  organization, or to devote the same resources to security basics and literacy training of all
  employees in the organization?"; or "Is it a better return on investment to train 'front-end'
  systems designers and developers in building security rules commensurate with the sensitivity
  of the system, or to train 'back-end' users in compliance with currently existing system rules?"
  Determination of the purpose and objectives of a Level 4 evaluation, as well as the number of
  variables and the method of measurement of skill level, should only be done following
  completion of Level 3 evaluation(s), utilizing the findings thereof.


5.4 implementation of Evaluation Planning


The information in Exhibit 5-1 should help in starting a comprehensive evaluation effort of an
organization's IT security training program. Each cell suggests the overall skill objective which
should be attained by the cell evaluator (e.g., instructor, or the student's supervisor, as
appropriate) and/or the overall program evaluator with respect to the various types of learning
programs. Each cell also produces a variety of specific information and requires different tools.


Because of the vast amount of data collected, evaluation tools usually consist of a series of
questions which require response on a Likert-type scale.     This scale, from one to five (one being
very good; five being not good, or vice versa), allows the evaluator to prioritize the usefulness of
the overall training program and the specific courses or learning events or components within it.
Each tool is program- and site-specific.

A practical method to use is to choose a starting point in Exhibit 5-1, beginning with a type of
training the organization currently offers; then find an evaluation tool appropriate to a cell at that
level and borrow or adapt the concepts presented from already-developed tools.       Samples of
some of these evaluation tools appear as Exhibits 5-2 and 5-3. Agency training staff may be able
to help locate other tools.


(Text continues after exhibits, on page 170.)




Chapters. Evaluating Training Effectiveness       163
