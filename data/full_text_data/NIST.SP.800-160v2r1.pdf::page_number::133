                                                                                                 NIST SP 800-160, VOL. 2, REV. 1                                         DEVELOPING CYBER-RESILIENT SYSTEMS
                                                                                                 _________________________________________________________________________________________________


                                                                                                 and programmatic environments, which can change physical, supply chain, personnel, technical,
                                                                                                 and procedural aspects of the attack surface, as well as technical aspects.

                                                                                                 D.5.1.4 Assume Compromised Resources
                                                                                                 A significant number of system architectures treat many, if not all, resources as non-malicious.
                                                                                                 This assumption is particularly prevalent in cyber-physical systems (CPS) and Internet of Things
                                                                                                 (IoT) architectures [Folk15]. However, systems and their components, ranging from chips to
                                                                                                 software modules to running services, can be compromised for extended periods without
                                                                                                 detection [DSB13]. In fact, some compromises may never be detected. Thus, the assumption
                                                                                                 that some system resources have been compromised is prudent. While the assumption that
This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.800-160v2r1




                                                                                                 some resources cannot be trusted is well established from the standpoint of security (i.e., the
                                                                                                 compromised resources cannot be trusted to follow established security policies), the concept
                                                                                                 of trustworthiness is broader. By compromising a resource, an adversary can affect its reliability,
                                                                                                 the ability to enforce other policies, or the safety of the larger system or environment of which
                                                                                                 the resource is a part or can use the resource in an attack on other systems [SP 1500-201]
                                                                                                 [NIST16].

                                                                                                 This design principle implies the need for analysis of how the system architecture reduces the
                                                                                                 potential consequences of a successful compromiseâ€”in particular, the duration and degree of
                                                                                                 adversary-caused disruption and the speed and extent of malware propagation. An increasing
                                                                                                 number of modeling and simulation techniques support the analysis of the potential systemic
                                                                                                 consequences stemming from the compromise of a given resource or set of resources. Such
                                                                                                 analysis includes identifying different types or forms of systemic consequences (e.g., unreliable
                                                                                                 or unpredictable behavior of services, unreliable or unpredictable availability of capabilities, or
                                                                                                 data of indeterminate quality) and subsequently linking these systemic consequences to mission
                                                                                                 consequences (e.g., mission failure, safety failure) or organizational consequences (e.g., loss of
                                                                                                 trust or reputation).

                                                                                                 D.5.1.5 Expect Adversaries to Evolve
                                                                                                 Advanced cyber adversaries invest time, effort, and intelligence gathering to improve existing
                                                                                                 TTPs and develop new TTPs. Adversaries evolve in response to opportunities offered by new
                                                                                                 technologies or uses of technology, as well as to the knowledge they gain about defender TTPs.
                                                                                                 In (increasingly short) time, the tools developed by advanced adversaries become available to
                                                                                                 less sophisticated adversaries. Therefore, systems and missions need to be resilient in the face
                                                                                                 of unexpected attacks. This design principle supports a risk management strategy that includes
                                                                                                 and goes beyond the common practice of searching for and seeking ways to remediate known
                                                                                                 vulnerabilities (or classes of vulnerabilities). A system that has been hardened in the sense of
                                                                                                 remediating known vulnerabilities will remain exposed to evolving adversaries.

                                                                                                 This design principle implies the need for analyses in which the adversary perspective is
                                                                                                 explicitly represented by intelligent actors who can play the role of an adaptive or evolving
                                                                                                 adversary. For implemented systems, such analyses are typically part of red teaming or war
                                                                                                 gaming. Analyses can use threat intelligence or repositories of attack patterns (e.g., ATT&CK
                                                                                                 [MITRE18], CAPEC [MITRE07]) to provide concrete examples, but care should be taken not to be
                                                                                                 constrained by those examples. Voice of the Adversary (VoA) is a design analysis technique in
                                                                                                 which one or more team members play the role of an adversary to critique alternatives by
                                                                                                 taking into consideration possible goals, behaviors, and cyber effects assuming varying degrees



                                                                                                 APPENDIX D                                                                                        PAGE 117
