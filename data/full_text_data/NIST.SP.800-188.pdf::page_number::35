NIST SP 800-188
September 2023



while still preserving many of the potential benefts, such as increased data-sharing and
improved decision-making.

3.2.1.     Probability of Re-Identifcation
As discussed in Sec. 2.2, “Terminology,” potential impacts on individuals include inferen-
tial disclosure. Dwork [49, p. 1] frst noted that “In 1977 Dalenius articulated a desideratum
for statistical databases: nothing about an individual should be learnable from the database
that cannot be learned without access to the database.” She proved “a general impossibility
showing that a formalization of Dalenius’ goal along the lines of semantic security cannot
be achieved.” Dwork and Naor [50, p. 95] proved that for any useful output algorithm,
“there exists auxiliary information that an adversary might possess in the context of which
the output ... would be disclosive.” Both papers refne the defnition of inferential disclosure
to distinguish between a confdentiality or privacy breach and a scientifc or generalizable
inference by “shift[ing] from absolute guarantees about disclosures to relative ones: any
given disclosure – indeed, any output at all of the privacy mechanism – should be, within a
small multiplicative factor, just as likely independent of whether any individual opts in to,
or opts out of, the database” [50, p. 103].
It is necessary to “distinguish between identity and attribute inferences that depend upon
the use of the protected entity’s data and those that are possible without using the protected
entity’s information” [7, p. 12]. A confdentiality breach occurs when an inference about
the attribute associated with a particular entity depends too much on the use of that en-
tity’s data in producing the statistical output. According to Kifer et al. [88, p. 4], “(t)he
differential privacy framework for SDL methods is designed precisely for the purpose of
distinguishing between confdentiality breaches and valid scientifc inferences.”
Re-identifcation probability16 is the probability that an individual’s identity will be cor-
rectly inferred by an outside party using information contained in a de-identifed dataset.
This outside party was originally termed a data intruder, although the terms adversary and
attacker are also used in the literature, borrowing from the colorful language of information
security.
Different kinds of re-identifcation probabilities for this data intruder can be calculated.
Here are several kinds of probabilities, as well as proposals for new, declarative, self-
describing names:
Known inclusion re-identifcation probability (KIRP) is the probability of fnding a record
    that matches a specifc individual known to be in the sample. KIRP can be expressed

16 Previous publications described identifcation probability as “re-identifcation risk” and used scenarios such

  as a journalist seeking to discredit a national statistics agency or a prosecutor seeking to fnd information
  about a suspect as the bases for probability calculations. That terminology is not presented in this document
  because of the possible unwanted connotations of those terms and in the interest of bringing the terminology
  of de-identifcation into agreement with the terminology used in contemporary risk analysis processes [55].


                                                     21
