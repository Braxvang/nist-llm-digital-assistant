NIST SP 800-188
September 2023



identifers but generally cannot identify or modify quasi-identifers in a manner consistent
with a privacy policy or risk analysis.
Data masking tools were developed to allow software developers and testers access to
datasets that contain realistic test data while providing minimal privacy protection. Absent
additional controls or data manipulations, data masking tools should not be used for the
de-identifcation of datasets that are intended for public release nor as the sole mechanism
to ensure confdentiality in non-public data sharing.

5.3.   Evaluating De-Identifcation Software
Once techniques are evaluated and approved, agencies should ensure that the techniques are
faithfully executed by their chosen software. Privacy software evaluation should consider
the trade-off between data usability and privacy protection. Privacy software evaluation
should also seek to detect and minimize the chances of tool error and user error.
For example, agencies should verify:
    • Correctness. The software properly implements the chosen algorithms.
    • Containment. The software does not leak identifying information in expected or
      unexpected ways, such as through the inaccuracies of foating-point arithmetic or the
      differences in execution time (if observable to a data intruder).
    • Usability. The software can be operated effciently and with minimal error, and users
      can detect and correct errors when they happen.
Agencies should also evaluate the performance of the de-identifcation software, such as:
    • Effciency. How long does it take to run on a dataset of a typical size?
    • Scalability. How much does it slow down when moving from a dataset of N to 100N?
    • Repeatability. If the tool is run twice on the same dataset, are the results similar? If
      two different people run the tool, do they get similar results?
    • Transparency. Is the tool’s algorithm documented? Is the tool’s source code avail-
      able? Is it possible for interested researchers or members of the public to obtain the
      tool and test it for themselves? These characteristics are common for open-source
      software but may not be present in proprietary software.
Ideally, software should be able to track the accumulated privacy leakage from multiple
data releases.

5.4.   Evaluating Data Accuracy
The feld of statistical disclosure limitation (SDL) has developed approaches for gauging
the impact of SDL techniques on microdata [172]. The literature examines the mathe-


                                             74
