NIST SP 800-188
September 2023



    • Critically evaluating all default assumptions used by software that performs data
      modifcation or modeling.
    • Conducting a motivated intruder test to see if reasonably competent outside indi-
      viduals can perform re-identifcation using publicly available datasets, commercially
      available datasets, or even private datasets that might be available to certain data
      intruders. Motivations for an intruder can include prurient interest, causing embar-
      rassment or harm, revealing private facts about public fgures, or engaging in a rep-
      utation attack. Details for how to conduct a motivated intruder test can be found in
      Anonymisation: Managing data protection risk code of practice, published by the
      United Kingdom’s Information Commissioner’s Offce [81].
    • Providing the team conducting the motivated intruder test with some confdential
      agency data to understand how a data intruder might be able to take advantage of
      data leaked as a result of a breach or a hostile insider.
Ideally, studies should report re-identifcation results for such motivated intruder tests for
both vulnerable populations and the general population.
These approaches do not provide provable guarantees on the protection offered by formal
privacy techniques, but they may be useful as part of an overall agency risk assessment.37
Applications that require provable privacy guarantees should rely on formal privacy meth-
ods, such as differential privacy, when planning their data releases.
Validating the privacy protection of de-identifed data is greatly simplifed by using vali-
dated de-identifcation software, as discussed in Sec. 5, “Re-Identifcation Studies.”

4.6.3.    Re-Identifcation Studies
Re-identifcation studies are motivated intruder tests. These studies can identify issues that
would allow external actors to successfully re-identify de-identifed data. Re-identifcation
studies look for vulnerabilities in a dataset that could be used for re-identifying data sub-
jects. They do not determine whether someone with intimate knowledge of a specifc re-
spondent can fnd that respondent in the database. The only way to protect a single specifc
individual perceived to be at high risk of re-identifcation is through data perturbation (e.g.,
noise addition) or information reduction (e.g., removing the observation altogether).


37 Although other documents that discuss de-identifcation use the term risk assessment to refer to a specifc

 calculation of ambiguity using the k-anonymity de-identifcation model, this document uses the term risk
 assessment to refer to a much broader process. Specifcally, risk assessment is defned as, “The process
 of identifying, estimating, and prioritizing risks to organizational operations (including mission, functions,
 image, reputation), organizational assets, individuals, other organizations, and the Nation, resulting from
 the operation of an information system. Part of risk management incorporates threat and vulnerability
 analyses and considers mitigations provided by security controls planned or in place. Synonymous with
 risk analysis” [149].


                                                     69
