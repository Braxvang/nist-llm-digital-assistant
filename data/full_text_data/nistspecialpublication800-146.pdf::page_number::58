                                                              CLOUD COMPUTING SYNOPSIS AND RECOMMENDATIONS



message to travel to a provider plus the time it takes for the response message to be received by a
consumer. Generally, Internet round-trip times are not a single expected number but instead a range, with
a significant amount of variability caused by congestion, configuration error, or failures. These factors
are often not under the control of a provider or consumer. However, wide area network optimization
technologies and web application acceleration services exist that may be employed to mitigate
unacceptable performance. The suitability of an application for such an environment requires a careful
analysis of the application's criticality, its built-in tolerance for variations in network service response
times, and possible remediation(s) that can be applied after the fact. Note that this last statement is not
unique to clouds.

8.1.2    Off-line Data Synchronization

Access to documents stored in clouds is problematic when consumers do not have network connectivity.
The ability to synchronize documents and process data, while the consumer is offline and with documents
stored in a cloud, is desirable, especially for SaaS clouds. Accomplishing such synchronization may
require version control, group collaboration, and other synchronization capabilities within a cloud.

8.1.3    Scalable Programming

Programming “in the large” using toolkits such as MapReduce [Dea04], BigTable [Cha06], or even
scalable queue services requires a new examination of application development practices. The ability to
dynamically request additional computing capacity brings well-researched computing models such as grid
computing and parallel processing out of scientific research labs and into more general computing usage.
Cloud users can leverage data- and task-parallelism to take advantage of additional computing capacity,
as well as to better scale computationally intensive tasks. Applications will likely, however, need to be
reengineered to realize the full benefits of the new computing capacity that is now available on demand.

8.1.4    Data Storage Management

When data storage is considered in the context of clouds, consumers require the ability to: (1) provision
additional storage capacity on demand, (2) know and restrict the physical location of the stored data, (3)
verify how data was erased, (4) have access to a documented process for securely disposing of data
storage hardware, and (5) administer access control over data. These are all challenges when data is
hosted by an external party.

8.2     Cloud Reliability

Reliability refers to the probability that a system will offer failure-free service for a specified period of
time within the bounds of a specified environment. For the cloud, reliability is broadly a function of the
reliability of four individual components: (1) the hardware and software facilities offered by providers,
(2) the provider’s personnel, (3) connectivity to the subscribed services, and (4) the consumer’s
personnel.

Note that measuring the reliability of a specific cloud by the provider or consumer will be difficult for two
main reasons. Firstly, a cloud may be a composition of various components, each inheriting a particular
degree of reliability when it was measured as a standalone entity. When these components are combined,
the resulting reliability is difficult to predict and may wind up being too course-grained. Secondly,
reliability measurement is a function of an environment, and it may not be possible to fully understand the
entire environment in which a cloud operates. As stated, the traditional definition of reliability is based
on a context (environment) and a specified period of time for expected failure-free operation. For clouds,




                                                     8-2
