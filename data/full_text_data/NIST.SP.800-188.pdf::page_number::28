NIST SP 800-188
September 2023



techniques for de-identifcation require an expert to make this distinction and protect only
the identifying information. Indeed, as understanding of privacy risk develops, it is increas-
ingly apparent that all information is potentially identifying information, and it is necessary
to thoughtfully engage in prioritizing the concerns of balancing privacy threats with scien-
tifc data accuracy.
This document envisions a de-identifcation process in which an original dataset that con-
tains personal information is algorithmically processed to produce de-identifed data. The
result may be a de-identifed dataset; aggregate statistics, such as summary tables; or a
synthetic dataset in which the data are created by a model. This kind of de-identifcation
is envisioned as a batch process. Alternatively, the de-identifcation process may be a
system that accepts queries and returns responses that do not leak more identifying infor-
mation than is allowable by policy. De-identifed results may be corrected or updated and
re-released on a periodic basis. The accumulated leakage of information from multiple
releases may be signifcant, even if the leakage from a single release is small. Issues that
arise from multiple releases are discussed in Sec. 3.4, “Data-Sharing Models.”
Disclosure is generally the exposure of data beyond the original collection use case. Ac-
cording to the traditional SDL literature,
      “Disclosure relates to inappropriate attribution of information to a data sub-
      ject, whether an individual or an organization. Disclosure occurs when a data
      subject is identifed from a released fle (identity disclosure), sensitive infor-
      mation about a data subject is revealed through the released fle (attribute dis-
      closure), or the released data substantially make it possible to determine the
      value of some characteristic of an individual more accurately than otherwise
      would have been possible (inferential disclosure).” [132, p. 23–24, emphasis
      in original]
A similar defnition appears in the Glossary of Statistical Terms:
      Disclosure
      Disclosure relates to the inappropriate attribution of information to a data sub-
      ject, whether an individual or an organisation. Disclosure has two components:
      identifcation and attribution. [71]
This traditional defnition for disclosure can be ambiguous and can produce incorrect con-
clusions. An alternative formulation in plain language is that a confdentiality breach oc-
curs when an inference about the attribute associated with a particular entity is improved
through the use of that entity’s data in producing the statistical output. Privacy-eroding
inference in this manner is distinct from inferences that can be drawn independent of the
entity’s data and through generalizable inference from the larger population.
The defnitions from differential privacy are more nuanced than those from traditional SDL.
They put a bound on the relative probability of disclosure by comparing when an individual
is in the frame and out of the frame (either by removal or replacement from the frame) [49,

                                              14
