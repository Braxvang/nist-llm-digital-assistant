A STATISTICAL TEST SUITE FOR RANDOM AND PSEUDORANDOM NUMBER GENERATORS FOR CRYPTOGRAPHIC APPLICATIONS



            Another, frequently asked question concerns the need for applying a monobits test (i.e.,
            Frequency test), in lieu of Maurer’s Universal Statistical test. The perception is that Maurer's
            Universal Statistical test supercedes the need to apply a monobits test. This may hold true for
            infinite length sequences. However, it is important to keep in mind that there will be
            instances when a finite binary sequence will pass Maurer's Universal Statistical test, yet fail
            the monobits test. Because of this fact, NIST recommends that the Frequency test be applied
            first. If the results of this test support the null hypothesis, then the user may proceed to apply
            other statistical tests.


4.4 Application of Multiple Tests
Given a concern regarding the application of multiple tests, NIST performed a study to determine the
dependence between the tests. The performance of the tests was checked by using a Kolmogorov-
Smirnov test of uniformity on the P-values obtained from the sequences. However, it required an
assumption that the sequences that were generated to test uniformity were sufficiently random. There are
many tests in the suite. Some tests should intuitively give independent answers (e.g., the frequency test
and a runs test that conditions on frequencies should assess completely different aspects of randomness).
Other tests, such as the cusum test and the runs test, result in P-values that are likely to be correlated.

To understand the dependencies between the tests in order to eliminate redundant tests, and to ensure that
the tests in the suite are able to detect a reasonable range of patterned behaviors, a factor analysis of the
resulting P-values was performed. More precisely, in order to assess independence, m sequences of
binary pseudorandom digits were generated, each of length n, and all k=161 tests in the suite were applied
to those sequences to determine their randomness. Each test produced a significance probability; denote
by pij the significance probability of test i on sequence j.

                                                                     ( )
Given the uniformly distributed pij , the transformation z ij = Φ −1 pij leads to normally distributed
variables. Let zj be the vector of transformed significance probabilities corresponding to the ith sequence.
A principal components analysis was performed on the z1, … , zm. Usually, a small number of
components suffices to explain a great proportion of the variability, and the number of these components
can be used to quantify the number of “dimensions'” of nonrandomness spanned by the suite tests. The
principal component analysis of this data was performed. This analysis extracts 161 factors, equal to the
number of tests. The first factor is the one that explains the largest variability. If many tests are
correlated, their P-values will greatly depend on this factor, and the fraction of total variability explained
by this factor will be large. The second factor explains the second largest proportion of variability, subject
to the constraint that the second factor is orthogonal to the first, and so on for subsequent factors. The
corresponding fractions corresponding to the first 50 factors were plotted for the tests, based on Blum-
Blum-Shub sequences of length 1,000,000. This graph showed that there is no large redundancy among
our tests.

The correlation matrix formed from the z1, … , zm was constructed via a statistical software application
(SAS). The same conclusion was supported by the structure of these matrices. The degree of duplication
among the tests seems to be very small.




                                                     4-6
