      these properties and how it satisfies the reporting requirements for those properties, where
      appropriate.

            Similarity preservation: Similarity digests must be constructed such that the
            outcome of a comparison between any two digests is uniquely determined by the
            similarity of the artifacts from which they were produced. That is, if A is a
            similarity digest created from artifact A and B is a similarity digest created from
            artifact B, the results of comparing A and B should be uniquely determined by
            the similarity of A and B.
            Self-evaluation: The similarity measure should be accompanied by a measure of
            the accuracy of the matching technique under the circumstances in which it is
            used, e.g., a margin of error or confidence level. The description of the output
            score should also state whether a score of 1 indicates an exact match.
            Compression: A compact similarity digest is desired as it normally allows a
            faster comparison and requires less storage space. In the best case, it will have a
            fixed length like the output of traditional hash functions. If the efficiency and
            reliability of the results remains unchanged, then a shorter similarity digest is
            preferable.
            Ease of computation: First, the algorithm description should include the results
            of testing the runtime efficiency of the feature extraction function and of the
            similarity function. The former might be expressed relative to a standard hashing
            algorithm, such as SHA-1.
            Second, the algorithm description should state the theoretical complexity for a
            similarity digest comparison in big O notation. For instance, common lookup
            complexities for comparing a single digest against a database with n entries, are:
                O(1)      for fixed-length digests stored in hash tables (e.g. dictionaries)
                O(log2 n) for fixed-length digests stored in binary trees or a sorted list
                O(n)      for fixed-length digests stored in an unsorted list, or other
                          scenarios in which no indexing or sorting is possible

2.4   Reliability of results

      The reliability of the results for a given approximate matching technique depends on three
      factors. Each algorithm should define how it incorporates these factors and how it satisfies
      their reporting requirements.

           Sensitivity & robustness: The algorithm should provide some measure of its
           robustness. A technique’s robustness will define the operating conditions in which
           it can function effectively, also called its performance envelope. For example,
           robustness addresses the minimum and maximum sizes of objects that an
           algorithm can reliably distinguish between.
           Precision & recall: The algorithm should include a description of the methods
           used to determine its reliability and to select the test data. Specifically, it should
           indicate whether test data is culled from existing collections or developed solely to
           support testing. Test results may include precision, recall, F-score, and other
           relevant measures of effectiveness.


                                                 5
