GUIDE TO COMPUTER SECURITY LOG MANAGEMENT



         –    Log compression is storing a log file in a way that reduces the amount of storage space
              needed for the file without altering the meaning of its contents. Log compression is often
              performed when logs are rotated or archived.

         –    Log reduction is removing unneeded entries from a log to create a new log that is smaller. A
              similar process is event reduction, which removes unneeded data fields from all log entries.
              Log and event reduction are often performed in conjunction with log archival so that only the
              log entries and data fields of interest are placed into long-term storage.

         –    Log conversion is parsing a log in one format and storing its entries in a second format. For
              example, conversion could take data from a log stored in a database and save it in an XML
              format in a text file. Many log generators can convert their own logs to another format; third-
              party conversion utilities are also available. Log conversion sometimes includes actions such
              as filtering, aggregation, and normalization.

         –    In log normalization, each log data field is converted to a particular data representation and
              categorized consistently. One of the most common uses of normalization is storing dates and
              times in a single format. For example, one log generator might store the event time in a
              twelve-hour format (2:34:56 P.M. EDT) categorized as Timestamp, while another log
              generator might store it in twenty-four (14:34) format categorized as Event Time, with the
              time zone stored in different notation (-0400) in a different field categorized as Time Zone.24
              Normalizing the data makes analysis and reporting much easier when multiple log formats
              are in use. However, normalization can be very resource-intensive, especially for complex
              log entries (e.g., typical intrusion detection logs).

         –    Log file integrity checking involves calculating a message digest for each file and storing the
              message digest securely to ensure that changes to archived logs are detected. A message
              digest is a digital signature that uniquely identifies data and has the property that changing a
              single bit in the data causes a completely different message digest to be generated. The most
              commonly used message digest algorithms are MD5 and Secure Hash Algorithm 1 (SHA-
              1).25 If the log file is modified and its message digest is recalculated, it will not match the
              original message digest, indicating that the file has been altered. The original message
              digests should be protected from alteration through FIPS-approved encryption algorithms,
              storage on read-only media, or other suitable means.
      Analysis

         –    Event correlation is finding relationships between two or more log entries. The most
              common form of event correlation is rule-based correlation, which matches multiple log

24
     Normalizing times is often particularly challenging. Organizations with systems in multiple time zones often need to
     convert all logged times to a single time zone. Also, systems’ clocks might not be in sync with each other, so it might be
     necessary to add or subtract times from the log entries recorded by out-of-sync sources. Organizations should use time
     synchronization technologies such as Network Time Protocol (NTP) servers whenever possible to keep log sources’ clocks
     consistent with each other.
25
     Federal agencies must use Federal Information Processing Standard (FIPS) approved encryption algorithms contained in
     validated cryptographic modules. Because SHA is a FIPS-approved algorithm and MD5 is not, Federal agencies must use
     SHA instead of MD5 for message digests. The Cryptographic Module Validation Program (CMVP) at NIST coordinates
     FIPS testing; the CMVP Web site is located at http://csrc.nist.gov/cryptval/. FIPS 180-2, Secure Hash Standard, is available
     at http://csrc nist.gov/publications/fips/fips180-2/fips180-2withchangenotice.pdf. SHA-1 has been the most commonly used
     version of SHA; however, NIST has announced that Federal agencies should plan on transitioning from SHA-1 to stronger
     forms of SHA (e.g., SHA-224, SHA-256) by 2010. For more information, see NIST comments from August 2004 posted at
     http://csrc nist.gov/hash standards comments.pdf, as well as http://www nsrl nist.gov/collision.html. Organizations should
     consider using SHA-256 instead of SHA-224 or SHA-1 if the operating systems or applications generating message digests
     support SHA-256.


                                                              3-4
