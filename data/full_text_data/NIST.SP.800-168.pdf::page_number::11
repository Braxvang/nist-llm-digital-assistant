             persistently stored. Semantic methods tend to provide the most specific results
             but also tend to be the most computationally expensive ones.

      In current literature, researchers use a number of terms to refer to various approximate
      matching methods: fuzzy hashing and similarity hashing denote bytewise approximate
      matching; perceptual hashing and robust hashing denote semantic approximate matching.
      There is no widely-used pre-existing terminology for syntactic approximate matching as it is
      mostly viewed as pre-processing (to separate the features) before hashing, or applying a
      bytewise approximate matching algorithms. For example, network flows are usually
      reconstructed before any processing is done on them.

      Bytewise approximate matching algorithms work in two phases. In the first, a similarity digest
      representation (also referred to as a signature or fingerprint) is generated from the original
      data. In the second phase, digests are compared to produce a similarity score. More precisely:

      Similarity digest. A similarity digest is a (compressed) representation of the original data
      object’s feature set that is suitable for comparison with other similarity digests created by the
      same algorithm. In most cases, the digest is much smaller than the original artifact and the
      original object is not recoverable from the digest.

      Every bytewise approximate matching technique requires at least two core functions:

             Feature extraction function: identifies and extracts features/attributes from each
             digital artifact. The mechanism by which features are picked and interpreted
             depends on the approximate matching algorithm. The representation of this
             collection is the similarity digest of the object.
             Similarity function: compares two similarity digests and outputs a score. The
             recommended approach is to assign a score s in the 0 ≤ s ≤ 1 range, where 0
             indicates no similarity and 1 indicates high similarity. This score represents a
             normalized estimate of the number of matching features in the feature sets
             corresponding to the artifacts from which the similarity digests were created.
             Normalization strategy: The similarity function can follow one of two
             normalization strategies, depending on whether the algorithm describes
             resemblance or containment. For resemblance queries, the number of matching
             features will be weighed against the total number of features in both objects. In
             the case of containment queries, the algorithm may disregard unmatched features
             in the larger of the objects’ two-feature sets.

      Because features and feature sets can be arbitrarily complex and, furthermore, deal with byte-
      level structures to which meaning is not clearly assigned, the interpretation of the similarity
      score can prove challenging. To address this problem, some approximate matching algorithms
      make use of an empirically determined threshold value to attempt to correlate bytewise
      similarity scores with higher-level properties of interest. In such cases, the similarity score can
      be treated as a confidence score, where results above the threshold value are considered likely
      to exhibit common human-recognizable traits.

2.3   Essential requirements

      Like traditional hash functions, there are several defining characteristics that approximate
      matching functions should exhibit. Each algorithm should define how it incorporates each of
                                                  4
