                                                                                             NIST SP 800-90B                                            RECOMMENDATION FOR THE ENTROPY SOURCES
                                                                                                                                                                USED FOR RANDOM BIT GENERATION




                                                                                                                                   Sequence Probability

                                                                                                                                   00‚Ä¶0         3.9837√ó10-53

                                                                                                                                   0101‚Ä¶01 4.4813√ó10-30

                                                                                                                                   011‚Ä¶1        1.4202√ó10-47

                                                                                                                                   10‚Ä¶0         6.4631√ó10-53
This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.800-90B




                                                                                                                                   1010‚Ä¶10 4.6288√ó10-30

                                                                                                                                   11‚Ä¶1         1.1021√ó10-47



                                                                                             The resulting entropy estimate is min(‚Äì log2 (4.6288√ó10-30)/128,1) = min(0.761,1) = 0.761.

                                                                                             6.3.4   The Compression Estimate

                                                                                             The compression estimate, proposed by Hagerty and Draper [HD12], computes the entropy rate of
                                                                                             a dataset, based on how much the dataset can be compressed. This estimator is based on the Maurer
                                                                                             Universal Statistic [Mau92]. The estimate is computed by generating a dictionary of values, and
                                                                                             then computing the average number of samples required to produce an output, based on the
                                                                                             dictionary. One advantage of using the Maurer statistic is that there is no assumption of
                                                                                             independence. When sequences with dependencies is tested with this statistic, the compression
                                                                                             rate is affected (and therefore the entropy), but an entropy estimate is still obtained. A calculation
                                                                                             of the Maurer statistic is efficient, as it requires only one pass through the dataset to provide an
                                                                                             entropy estimate.

                                                                                             Given a dataset from the noise source, the samples are first partitioned into two disjoint groups.
                                                                                             The first group serves as the dictionary for the compression algorithm; the second group is used
                                                                                             as the test group. The compression values are calculated over the test group to determine the mean,
                                                                                             which is the Maurer statistic. Using the same method as the collision estimate, the probability
                                                                                             distribution that has the minimum possible entropy for the calculated Maurer statistic is
                                                                                             determined. For this distribution, the entropy per sample is calculated as the lower bound on the
                                                                                             entropy that is present.

                                                                                             This entropy estimation method is only applied to binary inputs.

                                                                                             Given the input S = (s1, ‚Ä¶, sL), where si œµ A = {0,1},
                                                                                                                                                          ‚Ä≤
                                                                                                1. Let b = 6. Create a new sequence, ùëÜùëÜ ‚Ä≤ = (ùë†ùë†1‚Ä≤ , ‚Ä¶ , ùë†ùë†‚åäùêøùêø/ùëèùëè‚åã ), by dividing S into non-overlapping
                                                                                                   b-bit blocks. If L is not a multiple of b, discard the extra data.



                                                                                                                                                45
