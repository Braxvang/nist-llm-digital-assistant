NIST SP 800-188
September 2023



models, privacy-preserving data publishing, and privacy-preserving data mining, see NIST
IR 8053.
Many of the techniques discussed in this publication (e.g., fully synthetic data and differ-
ential privacy) currently have limited use within the Federal Government due to cost, time
constraints, and the sophistication required of practitioners. However, these techniques
are likely to see increased use as agencies seek to make datasets that include identifying
information available.

2.2.   Terminology
While each of the de-identifcation traditions has developed its own terminology and math-
ematical models, they share many underlying goals and concepts. Where terminology
differs, this document relies on the terminology developed in previous documents by the
U.S. Government and standards organizations. This document uses the terms privacy risk
and informational risk to refer in aggregate to various types of disclosure risk, as defned
later in this section.
De-identifcation is a “general term for any process of removing the association between
a set of identifying data and the data subject” [85]. This document is specifcally con-
cerned with de-identifcation techniques that have the goal of preventing or limiting dis-
closure risks to individuals and establishments while still allowing for the production of
aggregate statistics. As a result, this document devotes attention to noise-introducing tech-
niques, such as differential privacy and the creation of synthetic datasets that are based
on privacy-preserving models. De-identifcation takes an original dataset and produces
de-identifed data. This document uses the term dataset to refer to the collected data and
assumes that data collection is completed before de-identifcation begins. However, many
of the processes and techniques described are also applicable in other collection models
(e.g., streaming data).
Re-identifcation is the “process by which information is attributed to de-identifed data in
order to identify the individual to whom the de-identifed data relate”[117]. This defni-
tion is from the Organization for Economic Cooperation and Development (OECD) Legal
Instruments Recommendation of the Council on Health Data Governance (2016).
Re-identifcation risk is the likelihood that a third party can re-identify data subjects in a
de-identifed dataset. Re-identifcation risk is typically a function of the adverse impacts
that would arise if re-identifcation were to occur and the likelihood of occurrence. Re-
identifcation risk is a specifc form of privacy risk that can result from the release or use of
de-identifed data.
Redaction is the removal of information from a document or dataset for legal or security
purposes. Also known as suppression, redaction is a kind of de-identifying technique that
relies on the removal of information. In general, redaction alone is insuffcient to provide
formal privacy guarantees, such as differential privacy. Redaction may also reduce the

                                              12
