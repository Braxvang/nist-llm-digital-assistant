                                                                                             NIST SP 800-90B                                                              RECOMMENDATION FOR THE ENTROPY SOURCES
                                                                                                                                                                                  USED FOR RANDOM BIT GENERATION

                                                                                             6       Estimating Min-Entropy

                                                                                             One of the essential requirements of an entropy source is the ability to reliably create random
                                                                                             outputs. To ensure that sufficient entropy is input to an RBG construction in SP 800-90C, the
                                                                                             amount of entropy produced per noise source sample must be determined. This section describes
                                                                                             generic estimation methods that will be used to test the noise source and also the conditioning
                                                                                             component, when non-vetted conditioning components are used. It should be noted that the entropy
                                                                                             estimation methods described in this section rely on some statistical assumptions that may not hold
                                                                                             for all types of noise sources. The methods should not replace in-depth analysis of noise sources,
                                                                                             but should be used to support the initial entropy estimate of the submitter (see Requirement 3 in
                                                                                             Section 3.2.2). An example noise source analysis is provided in [HaFis15].
This publication is available free of charge from: https://doi.org/10.6028/NIST.SP.800-90B




                                                                                             Each estimator takes a sequence S = (s1, …, sL) as its input, where each si comes from an output
                                                                                             space A = {x1, …, xk} that is specified by the submitter. The estimators presented in this
                                                                                             Recommendation follow a variety of strategies, which cover a range of assumptions about the data.
                                                                                             For further information about the theory and origins of these estimators, see Appendix G. The
                                                                                             estimators that are to be applied to a sequence depend on whether the data has been determined to
                                                                                             be IID or non-IID. For IID data, the min-entropy estimation is determined as specified in Section
                                                                                             6.1, whereas for non-IID data, the procedures in Section 6.2 are used.

                                                                                             The estimators presented in this section work well when the entropy-per-sample is greater than
                                                                                             0.1. For alphabet sizes greater than 256, some of the estimators are not very efficient. Therefore,
                                                                                             for efficiency purposes, the method described in Section 6.4 can be used to reduce the alphabet
                                                                                             space of the outputs.

                                                                                             6.1     IID Track: Entropy Estimation for IID Data

                                                                                             For sources with IID outputs, the min-entropy estimation is determined using the most common
                                                                                             value estimate described in Section 6.3.1. It is important to note that this estimate typically
                                                                                             provides an overestimation when the samples from the source are not IID 11.

                                                                                             6.2     Non-IID Track: Entropy Estimation for Non-IID Data

                                                                                             Many viable noise sources fail to produce IID outputs. Moreover, some sources may have
                                                                                             dependencies that are beyond the ability of the tester to address. To derive any utility out of such
                                                                                             sources, a diverse and conservative set of entropy tests are required. Testing sequences with
                                                                                             dependent values may result in overestimates of entropy. However, a large, diverse battery of
                                                                                             estimates minimizes the probability that such a source’s entropy is greatly overestimated.



                                                                                             11 However, it is possible for this estimate to slightly underestimate the true min-entropy. It is believed that this underestimation is

                                                                                             likely to not exceed one bit because of the relationship between min-entropy and the expected guessing work derived in Appendix
                                                                                             D. Of course, such an underestimate would not indicate that a guessing attack that ignores dependencies could be less costly than
                                                                                             one that takes the dependencies into account. As an example, consider a data sample consisting of pairs of bytes generated from
                                                                                             the joint distribution on two bytes X and Y, each having possible values A and B, where Pr(X=A, Y=A)=0.104,
                                                                                             Pr(X=A,Y=B)=0.332, Pr(X=B,Y=A)=0.239, and Pr(X=B,Y=B)=0.325. The min-entropy according to the MCV estimator is 0.712,
                                                                                             while the true min-entropy is 0.795.


                                                                                                                                                               40
