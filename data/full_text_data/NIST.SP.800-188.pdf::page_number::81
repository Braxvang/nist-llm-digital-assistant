NIST SP 800-188
September 2023



                                 ̸ 1. Principled approaches for setting ε are a subject of
invariably result in values of ε =
current academic research [93, 93, 92, 104].
There are relatively few scholarly publications regarding the deployment of differential pri-
vacy in real-world situations, and there are few papers that provide guidance on choosing
appropriate values of ε. Thus, agencies that are interested in using differential privacy algo-
rithms to allow for the querying of sensitive datasets or the creation of synthetic data should
ensure that the techniques are appropriately implemented and that the privacy protections
are appropriate for the desired application. Tools area now under development to help
visualize and understand the error and risks associated with different privacy parameters.
Despite these diffculties, differential privacy has been successfully used in a growing num-
ber of real-world deployments, including the Census Bureau’s OnTheMap interactive tool,
the 2020 Census, and the College Scorecard website developed by the Internal Revenue
Service and the U.S. Department of Education.
For additional information, please see the NIST Differential Privacy blog series at https://
www.nist.gov/itl/applied-cybersecurity/privacy-engineering/collaboration-space/focus-areas/
de-id/dp-blog, and the NIST de-identifcation tool location at https://www.nist.gov/itl/applied-
cybersecurity/privacy-engineering/collaboration-space/focus-areas/de-id/tools.

4.5.    De-Identifying with an Interactive Query Interface
Another model for granting public access to de-identifed agency information is to construct
an interactive query interface that allows members of the public or qualifed investigators to
run queries over the agency’s dataset. This option has been developed by several agencies,
and there are many ways that it can be implemented. For example:
    • If the queries are run on actual data, the results can be altered through the addition
      of noise to protect privacy, potentially satisfying a formal privacy model, such as
      differential privacy. Alternatively, individual queries can be reviewed by agency staff
      to verify that privacy thresholds are maintained.
    • Queries can be run on synthetic data. In this case, the agency can also run queries
      on the actual data and warn the external researchers if the queries run on synthetic
      data deviate signifcantly from the queries run on the actual data (ensuring that the
      warning itself does not compromise the privacy of some individual).
    • Query interfaces can be made freely available on the public internet, or they can be
      made available in a restricted manner to qualifed researchers operating in secure
      locations.
A signifcant privacy risk with interactive queries is that each query results in additional
privacy loss [44].36 That is, the query interface alone will not protect privacy but should
36 If a fnite privacy loss budget is allocated, the data controller needs to respond by increasing the amount of

  noise added to each response, accepting a higher level of privacy risk, or ceasing to answer questions as the


                                                      67
