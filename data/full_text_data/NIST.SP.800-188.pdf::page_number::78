NIST SP 800-188
September 2023



    • Many hypotheses not represented exactly in the original model may be informed by
      the synthetic data because they are correlated with hypotheses (effects) that are in the
      model.
    • Some users may place more trust in a synthetic dataset than in a model.
    • When researchers form their hypotheses from synthetic data and then verify their
      fndings on actual data, they can be protected from pretest estimation and false dis-
      covery bias [8, p. 257].
Because of the possibility of false discovery, analysts should be able to validate their dis-
coveries against the original data to ensure that the things they discover are in the original
data and not artifacts of the data generation process.
Both high-fdelity models and synthetic data generated from models may leak personal
information that is potentially re-identifable. The amount of leakage can be controlled us-
ing formal privacy models (e.g., differential privacy) that typically involve the introduction
of noise. Section 4.4.7 describes the construction of fully synthetic data with differential
privacy.
There are several advantages for agencies that choose to release de-identifed data as a fully
synthetic dataset:
    • It can be very diffcult to map records to actual people if the synthetic dataset is
      suffciently large.
    • The privacy guarantees can potentially be mathematically established and proven (
      Sec. 4.4.7).
    • The privacy guarantees can remain in force even if there are future data releases.
Fully synthetic data also have these disadvantages and limitations:
    • It is not possible to create pseudonyms that map back to actual people because the
      records are fully fabricated.
    • The data release may be less useful for accountability or transparency. For example,
      investigators equipped with a synthetic data release would be unable to fnd the actual
      “people” who make up the release because they would not actually exist.
    • For traditional models (such as Gaussian mixture models), it may be diffcult to fnd
      meaningful correlations or abnormalities in synthetic data that are not represented in
      the model. For example, if a model contains only main effects and frst-order inter-
      actions, then all second-order interactions can only be estimated from the synthetic
      data to the extent that their design is correlated with the main or frst-order interac-
      tions. For models based on modern deep learning techniques, it may be diffcult to
      quantify the extent to which the model is memorizing (and potentially re-generating)
      the training data.


                                             64
