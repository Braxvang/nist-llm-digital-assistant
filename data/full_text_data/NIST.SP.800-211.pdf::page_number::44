     FOCUS AREA 8



           the trustworthiness of AI systems; support and expand public-private partnerships;
           and engage with international parties.
       •   NIST published draft NISTIR 8269, A Taxonomy and Terminology of Adversarial
           Machine Learning, in FY 2019 as a step toward securing applications of AI,
           specifically adversarial machine learning (AML), and features a taxonomy of
           concepts and terminologies [32]. This NISTIR can inform future standards and best
           practices for assessing and managing machine learning security by establishing a
           common language and understanding of the rapidly developing AML landscape.
     NIST is also supporting fundamental research to measure and enhance the security
     and explainability of AI systems and advancing the application of AI to NIST metrology
     problems by bolstering AI expertise at NIST and enabling NIST scientists to draw
     routinely on machine learning and AI tools to gain a deeper insight into their research.
     NIST launched the AI Visiting Fellow program, which brings nationally recognized leaders
     in AI and machine learning to NIST to share their knowledge and experience and provide
     technical support.
     NIST research in AI is focused on how to measure and enhance the security and
     trustworthiness of AI systems. This includes participation in the development of
     international standards that ensure innovation, public trust, and confidence in systems
     that use AI technologies. In addition, NIST is applying AI to measurement problems to
     gain deeper insight into the research itself as well as to better understand AI’s capabilities
     and limitations. In FY 2019, the NCCoE also began developing a testbed to research and
     develop metrics and best practices to assess the vulnerabilities of AI models.




36


     NIST/ITL CYBERSECURITY PROGRAM ANNUAL REPORT | 2019
