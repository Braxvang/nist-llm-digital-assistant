                                                                              GUIDELINES ON SECURING PUBLIC WEB SERVERS



 EmailSiphon and Cherry Picker are bots specifically designed to crawl Web sites for electronic mail
  (e-mail) addresses to add to spam mailing lists. These are common examples of bots that may have a
  negative impact on a Web site or its users.

 Many spambots crawl Web sites for login forms to create free e-mail addresses from which to send
  spam or to spam blogs, guestbooks, wikis, and forums to boost the search engine rankings of a
  particular Web site.

 Screen scrapers retrieve content from Web sites to put up a copy on another server. These copies can
  be used for phishing or for attempting to generate ad revenue by having users visit the copy.

 Some malicious bots crawl Web sites looking for vulnerable applications containing sensitive data
  (e.g., Social Security Numbers [SSN], credit card data).

Bots can present a challenge to Webmasters’ administration of their servers because—

 Web servers often contain directories that do not need to be indexed.

 Organizations might not want part of their site appearing in search engines.

 Web servers often contain temporary pages that should not be indexed.

 Organizations operating the Web server are paying for bandwidth and want to exclude robots and
  spiders that do not benefit their goals.

 Bots are not always well written or well intentioned and can hit a Web site with extremely rapid
  requests, causing a reduction in responsiveness or outright DoS for legitimate users.

 Bots may uncover information that the Webmaster would prefer remained secret or at least
  unadvertised (e.g., e-mail addresses).

Fortunately, Web administrators or the Webmaster can influence the behavior of most bots on their Web
site. A series of agreements called the Robots Exclusion Protocol (REP) has been created. Although
REP is not an official Internet standard, it is supported by most well-written and well-intentioned bots,
including those used by most major search engines.

Web administrators who wish to limit bots’ actions on their Web server need to create a plain text file
named “robots.txt.” The file must always have this name, and it must reside in the Web server’s root
document directory. In addition, only one file is allowed per Web site. Note that the robots.txt file is a
standard that is voluntarily supported by bot programmers, so malicious bots (such as EmailSiphon and
Cherry Picker) often ignore this file. 28

The robots.txt file is a simple text file that contains some keywords and file specifications. Each line of
the file is either blank or consists of a single keyword and its related information. The keywords are used
to tell robots which portions of a Web site are excluded.



28
     Other methods for controlling malicious bots exist; however, they are changing constantly as the malicious bot operators and
     Web administrators develop new methods of counteracting each other’s techniques. Given the constantly changing nature
     of this area, discussion of these techniques is beyond the scope of this document. More information is available at
     http://www.onguardonline.gov/spam.html.


                                                              5-7
